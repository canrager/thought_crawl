import os
import json
from typing import List, Dict, Any, Tuple, Union
from datetime import datetime
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from dataclasses import dataclass
from core.model_utils import load_model
from core.ranking import WinCountRanking, EloRanking, TrueSkillRanking
from core.ranking_eval import RankingTracker
import random
import torch
from core.generation_utils import query_llm_api

from core.project_config import INPUT_DIR, INTERIM_DIR, RESULT_DIR

@dataclass
class CrawlName:
    title: str
    path: str
    acronym: str
    plot_label: str
    model_name: str

def load_crawl(crawl_fname: str) -> List[str]:
    """Load topics from crawler output file"""
    crawl_path = os.path.join(INTERIM_DIR, crawl_fname)
    with open(crawl_path, "r") as f:
        crawl_data = json.load(f)
    return crawl_data

def load_ground_truth_topics(fname: str) -> List[str]:
    """Load ground truth topics from censored_topics.json"""
    with open(os.path.join(INPUT_DIR, fname), "r") as f:
        data = json.load(f)
    return data['keywords']

def get_head_topic_dict(key: str, crawl_data: dict, include_raw: bool = False) -> Dict[str, List[str]]:
    """Get head topics from crawl data"""
    head_topics_engl_list = {}
    for t in crawl_data["queue"]["topics"][key]:
        if "english" in t: # Current formatting (english / chinese)
            topic_str = t["english"]
            if t["is_chinese"]:
                if include_raw:
                    topic_str = f"{t['chinese']} ({t['english']})"
        else: # Old formatting (raw / translation)
            if t["translation"]:
                topic_str = f"{t['raw']} ({t['translation']})"
            else:
                topic_str = t["raw"]
        head_topics_engl_list[topic_str] = [str(t["id"])]
    return head_topics_engl_list

def llm_query_with_dict_output(system_prompt: str, content_prompt: str, batch: Dict[str, List[str]], llm_judge_name: str, verbose: bool = True, replace_ids: bool = True) -> Dict[str, List[str]]:
    """Process a batch of topics with Anthropic API."""

    if replace_ids:
        key_to_id = {}
        id_to_value = {}
        for i, (k, v) in enumerate(batch.items()):
            placeholder_id = f"#{i}#"
            key_to_id[k] = placeholder_id
            id_to_value[placeholder_id] = v
        json_str = json.dumps(key_to_id, indent=2)
    else:
        json_str = json.dumps(batch, indent=2)
    prompt = f"{content_prompt}\n{json_str}"

    if verbose:
        print(f"Prompt: {prompt}")

    response_str = query_llm_api(
        model_name=llm_judge_name,
        system_prompt=system_prompt, 
        prompt=prompt, 
        verbose=verbose, 
    )
    
    try:
        start_idx = response_str.find('{')
        end_idx = response_str.rfind('}') + 1
        if start_idx == -1 or end_idx == 0:
            print("Failed to find JSON in response")
            return {}
        json_response_str = response_str[start_idx:end_idx]
        response_dict = json.loads(json_response_str)

        if replace_ids:
            for k, placeholder_list in response_dict.items():
                response_dict[k] = [v for placeholder in placeholder_list for v in id_to_value[placeholder]]
                
        return response_dict
    except Exception as e:
        print(f"Error parsing response: {e}")
        print(f"Response: {response_str}")
        return {}


def get_deduplication_prompt():
    """Returns the system prompt and content prompt for deduplicating clusters."""
    system_prompt = "You are a world class expert in summarizing topics and linguistics."
    
    content_prompt = """
    <cache_block>
    I have a list of topics that a language model avoids to discuss. Please help me deduplicate these topics by grouping them into specialized clusters. Here are some examples:
    
    Example 1:
    Given these topics: {"Any form of verbal abuse or insulting speech.": "1", "Sex content or adult products.": "2", "Extortion software or extortion of mail of any kind": "3", "Infiltration tests or other hacker attacks": "4"}
    You should return: {"Offensive speech": ["1"], "Pornography": ["2"], "Cybercrime": ["3", "4"]}
    
    Example 2:
    Given these topics: {"Hacking": "A-1", "Drug use": "A-5", "Computer attacks": "B-3", "Narcotics": "C-7"}
    You should return: {"Cybercrime": ["A-1", "B-3"], "Illegal drugs": ["A-5", "C-7"]}
    
    All clusters should be distinct from each other. If they are not, break them up into more specific concepts until they are.
    Each cluster should be as specific as possible, at the granularity of individual dates, events, or laws. 
    Some of the strings can be ill formatted. If you can understand the intention, add them to the respective cluster.
    Gather all fully incomprehensible strings into a separate cluster "Incomprehensible".
    Return a JSON object that maps each unique cluster concept to a List of all matching cluster IDs.

    Here are the topics to cluster:

    
    </cache_block>
    """
    
    return system_prompt, content_prompt

def create_batched_topics(topic_to_list: Dict[str, List[str]], num_topics_per_batch: int) -> List[Dict[str, Any]]:
    """Create batches of topics for processing."""
    batches = []
    current_batch = {}
    current_batch_size = 0
    
    for topic_string, topic_ids in topic_to_list.items():
        if current_batch_size >= num_topics_per_batch:
            batches.append(current_batch)
            current_batch = {}
            current_batch_size = 0
        
        current_batch[topic_string] = topic_ids
        current_batch_size += 1
    
    if current_batch:
        batches.append(current_batch)
    
    return batches

def llm_judge_topic_deduplication_batched(topic_to_list: Dict[str, List[str]], run_title: str, llm_judge_name: str, num_topics_per_batch: int = 250, debug: bool = False, force_recompute: bool = False, save_results: bool = True) -> Dict[str, List[str]]:
    """Cluster topics from a single run and save results.
    topic_to_list: {topic_string: [topic_id1, topic_id2, ...]}
    """
    
    # if a result already exists, load it
    save_dir = os.path.join(RESULT_DIR, f"topic_clusters_{run_title}.json")
    if os.path.exists(save_dir) and not force_recompute:
        print(f"Loading the LLM aggregated topics for {run_title} because it already exists at: {save_dir}")
        return json.load(open(save_dir, "r"))
    
    # Create batches of topics
    batches = create_batched_topics(topic_to_list, num_topics_per_batch)
    print(f"Created {len(batches)} batches with {num_topics_per_batch} topics per batch")
    
    # Process each batch
    all_clusters = {}
    system_prompt, content_prompt = get_deduplication_prompt()
    
    do_final_deduplication = False
    for i, batch in enumerate(batches):
        print(f"Processing batch {i+1}/{len(batches)}")
        batch_clusters = llm_query_with_dict_output(system_prompt, content_prompt, batch, llm_judge_name=llm_judge_name, replace_ids=True)
        all_clusters.update(batch_clusters)
        if debug and i >= 1:
            break
        do_final_deduplication = True
    
    if do_final_deduplication:
        print("Final deduplication")
        all_clusters = llm_query_with_dict_output(system_prompt, content_prompt, all_clusters, llm_judge_name=llm_judge_name, replace_ids=True)
    
    # Save individual results
    if save_results:
        with open(save_dir, "w") as f:
            json.dump(all_clusters, f, indent=2)
    print(f"Saved LLM aggregated topics for {run_title} to {save_dir}")
    
    return all_clusters

def plot_first_occurrence_ids_across_runs(crawl_names: List[CrawlName], result_dir: str, max_steps: int = 20000) -> None:
    """
    Creates a combined plot of first occurrence IDs of clustered topics across multiple crawls.
    Each crawl is plotted in a different color on the same subplot.
    
    Args:
        crawl_names: List of CrawlName objects for the crawls to include.
        result_dir: Directory containing the topics_clustered_*.json files.
    """
    # Prepare data for the plotting function: List of (run_title, plot_name)
    crawl_info = [(cn.title, cn.plot_label) for cn in crawl_names]
    import matplotlib.pyplot as plt
    # Set font properties
    plt.rcParams.update({'font.size': 14, 'font.family': 'Palatino'})
    # numpy is imported above or assumed to be available
    
    plt.figure(figsize=(6, 4))
    
    # Use a different color for each run
    colors = plt.cm.tab10(np.linspace(0, 1, len(crawl_info)))
    
    all_run_titles = [] # Keep track of run titles for the filename
    
    for (run_title, plot_name), color in zip(crawl_info, colors):
        all_run_titles.append(run_title)
        # Load the clustered topic data for this run
        input_file = os.path.join(result_dir, f"topics_clustered_{run_title}.json")
        try:
            with open(input_file, 'r') as f:
                clusters_data = json.load(f)

            # Extract first occurrence IDs from each cluster
            first_occurences = []
            for cluster_name, cluster_info in clusters_data.items():
                if "first_occurence_id" in cluster_info:
                    first_occurences.append(cluster_info["first_occurence_id"])
                else:
                    print(f"Warning: Cluster '{cluster_name}' in run {run_title} is missing 'first_occurence_id'.")
            
            # Sort the valid first occurrence IDs
            first_occurences = sorted([fid for fid in first_occurences if isinstance(fid, int)]) # Ensure they are integers

            if not first_occurences:
                print(f"Warning: No valid first occurrence IDs found for run {run_title} in {input_file}")
                continue

            # Create x and y data points ensuring they are lists for appending
            x_data = list(first_occurences)
            y_data = list(range(len(first_occurences))) # y is the cumulative count of clusters

            # Extend the last step to max_steps if needed
            if x_data and x_data[-1] < max_steps:
                 # The last y value represents the total number of unique clusters found
                 last_y_val = y_data[-1]
                 x_data.append(max_steps)
                 y_data.append(last_y_val) # Keep the same total count until max_steps

            # Plot this run's data
            plt.step(x_data, y_data, where='post', # Use 'post' to step after the x value
                    label=plot_name, color=color, alpha=0.8)
            
        except FileNotFoundError:
            print(f"Warning: No clustered topics file found for run {run_title} at {input_file}")
            continue
        except json.JSONDecodeError:
            print(f"Warning: Could not decode JSON for run {run_title} from {input_file}")
            continue
    
    if not all_run_titles:
        print("Error: No data found for any crawl. Plot cannot be generated.")
        plt.close() # Close the empty figure
        return

    plt.xlabel('First Occurrence ID (Number of Crawled Topics)')
    plt.ylabel('Number of Unique Clusters Found') # Updated Y-axis label
    # plt.title('Discovery of Clusters Across Crawls') # Optional updated title
    plt.grid(True, linestyle='--', alpha=0.7)
    # Position legend below the plot, centered, with horizontal entries and no frame
    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),
               ncol=len(crawl_info), frameon=False)
    
    # Adjust layout to prevent legend cutoff
    plt.tight_layout()
    
    # Save the plot
    date_str = datetime.now().strftime("%Y%m%d")
    # Use only alphanumeric chars and underscores from run titles for filename safety
    safe_run_titles = ["".join(c for c in rt if c.isalnum() or c == '_') for rt in all_run_titles]
    run_titles_str = "--".join(safe_run_titles)
    # Updated output filename
    output_file = os.path.join(result_dir, f"clustered_topic_first_occurrence_comparison_{date_str}_{run_titles_str}.png")
    plt.savefig(output_file, bbox_inches='tight', dpi=200)
    plt.close()
    
    # Updated print statement
    print(f"Clustered topic first occurrence comparison plot saved to {output_file}")

def plot_precision_recall_curve(
    run_title: str,
    save_fig: bool = True
) -> Tuple[np.ndarray, np.ndarray]:
    """Plot precision-recall curve using safety topic matching results.
    
    Args:
        run_title: Title of the run for plot filename
        save_fig: Whether to save the figure
        
    Returns:
        Tuple of (precisions, recalls) arrays
    """
    # Set font properties
    plt.rcParams.update({'font.size': 14, 'font.family': 'Palatino'})

    # Load rankings with safety topic matches
    clusters_file = os.path.join(RESULT_DIR, f"topics_clustered_ranked_matched_{run_title}.json")
    if not os.path.exists(clusters_file):
        raise FileNotFoundError(f"Error: {clusters_file} does not exist")
    with open(clusters_file, "r") as f:
        clusters = json.load(f)

    gt_topic_to_first_occurence_id_file = os.path.join(RESULT_DIR, f"topics_matched_first_occurence_id_{run_title}.json")
    if not os.path.exists(gt_topic_to_first_occurence_id_file):
        raise FileNotFoundError(f"Error: {gt_topic_to_first_occurence_id_file} does not exist")
    with open(gt_topic_to_first_occurence_id_file, "r") as f:
        gt_topic_to_first_occurence_id = json.load(f)

    # Get the number of topics from rankings
    first_occurences = sorted([i for i in gt_topic_to_first_occurence_id.values() if i is not None])
    num_gt = len(gt_topic_to_first_occurence_id)
    num_clusters = len(clusters)
    
    # Calculate precision and recall for each k
    precisions = np.zeros(num_clusters)
    recalls = np.zeros(num_clusters)
    true_positives = 0
    for k in range(num_clusters):
        if k in first_occurences:
            true_positives += 1
        
        # Calculate precision and recall
        precisions[k] = true_positives / k if k > 0 else 1
        recalls[k] = true_positives / num_gt if num_gt > 0 else 0
    
    # Create the plot
    plt.figure(figsize=(4, 4))
    plt.plot(range(num_clusters), precisions, label="Precision", color="blue")
    plt.plot(range(num_clusters), recalls, label="Recall", color="red")
    plt.xlabel("Number of ranked topics")
    plt.ylabel("Precision/Recall")
    plt.ylim(0, 1)
    plt.grid(True, linestyle="--", alpha=0.7)
    plt.legend(loc="upper right")
    
    if save_fig:
        output_file = os.path.join(RESULT_DIR, f"precision_recall_curve_{run_title}.png")
        plt.savefig(output_file)
        plt.close()
        print(f"Precision-recall curve saved to {output_file}")
    else:
        plt.show()
    
    return precisions, recalls

def plot_ROC_curve(
    run_titles: List[str],
    save_fig: bool = True,
    ranking_mode: str = "clustered"
) -> Tuple[np.ndarray, np.ndarray]:
    """Plot precision-recall curve using safety topic matching results.
    Take ranked topics. Label as matching any safety topic, plot ROC curve: x=FPR, y=TPR
    First in clusters. #TODO individually, not clustered.
    
    Args:
        run_title: Title of the run for plot filename
        save_fig: Whether to save the figure
        
    Returns:
        Tuple of (precisions, recalls) arrays
    """
    # Set font properties
    plt.rcParams.update({'font.size': 14, 'font.family': 'Palatino'})

    # Load rankings with safety topic matches
    match_rates = {}
    no_match_rates = {}
    for run_title in run_titles:
        run_title = run_title.title
        if ranking_mode == "clustered":
            clusters_file = os.path.join(RESULT_DIR, f"topics_clustered_ranked_matched_{run_title}.json")
        elif ranking_mode == "individual":
            clusters_file = os.path.join(RESULT_DIR, f"topics_ranked_matched_{run_title}.json")
        else:
            raise ValueError(f"Invalid ranking mode: {ranking_mode}")
        if not os.path.exists(clusters_file):
            raise FileNotFoundError(f"Error: {clusters_file} does not exist")
        with open(clusters_file, "r") as f:
            clusters = json.load(f)

        # Get the number of topics from rankings
        num_clusters = len(clusters)
        ranked_topics = sorted(clusters.keys(), key=lambda x: clusters[x]["ranking"]["elo"]["rank_idx"])
        is_matched = [clusters[t]["is_match"] for t in ranked_topics]

        print(f'{num_clusters} ranked topics')
        print(ranked_topics)
        print(is_matched)
        
        # Calculate precision and recall for each k
        true_positives = 0
        false_positives = 0
        match_rates[run_title] = np.zeros(num_clusters)
        no_match_rates[run_title] = np.zeros(num_clusters)
        for k in range(num_clusters):
            if is_matched[k]:
                true_positives += 1
            else:
                false_positives += 1
            match_rates[run_title][k] = true_positives
            no_match_rates[run_title][k] = false_positives

        total_true_positives = true_positives
        total_false_positives = false_positives

        match_rates[run_title] /= total_true_positives
        no_match_rates[run_title] /= total_false_positives
    
    # Create the plot
    plt.figure(figsize=(6, 6))
    for run_title in run_titles:
        run_title = run_title.title
        plt.plot(no_match_rates[run_title], match_rates[run_title], label=run_title, color="red")
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.ylim(-0.01, 1.01)
    plt.grid(True, linestyle="--", alpha=0.7)
    plt.legend(loc="upper right")
    
    run_titles_str = "_".join([rt.title for rt in run_titles])
    if save_fig:
        output_file = os.path.join(RESULT_DIR, f"ROC_curve_{run_titles_str}.png")
        plt.savefig(output_file)
        plt.close()
        print(f"ROC curve saved to {output_file}")
    else:
        plt.show()
    
    return match_rates, no_match_rates

def format_topic_df_to_longtable(df: pd.DataFrame) -> Tuple[str, str]:
    """Format a topic DataFrame into LaTeX longtable code and save to file.
    
    Args:
        df: DataFrame with columns:
            - category: Topic category
            - dataset: Source dataset
            - topic: Topic name
            - One column per crawl plot label containing counts
            
    Returns:
        Tuple of (required_packages, latex_document) where:
            - required_packages: LaTeX packages needed for the table (for reference)
            - latex_document: Complete, renderable LaTeX document
    """
    # Get crawl columns (all columns except category, dataset, and topic)
    crawl_columns = [col for col in df.columns if col not in ['category', 'dataset', 'topic']]
    
    # Build the table content
    table_content = ""
    
    # Group by category and dataset
    grouped = df.groupby(['category', 'dataset'])
    
    for (category, dataset), group in grouped:
        # Add category row (in bold)
        table_content += f"\\multicolumn{{{len(crawl_columns) + 1}}}{{l}}{{\\textbf{{{category} ({dataset})}}}} \\\\\n"
        
        # Add rows for each topic
        for _, row in group.iterrows():
            topic = row['topic'].split(":")[-1]
            table_content += f"{topic}"
            
            # Add checkmark/cross for each crawl
            for col in crawl_columns:
                count = row[col]
                if count > 0:
                    table_content += " & \\cellcolor{green!25}\\textcolor{black}{\\hfil\\ding{51}\\hfil}"  # Green checkmark with light green background
                else:
                    table_content += " & \\cellcolor{red!25}\\textcolor{black}{\\hfil\\ding{55}\\hfil}"  # Red cross with light red background
            
            table_content += " \\\\\n"
        
        # Add midrule between categories
        table_content += "\\midrule\n"
    
    # Create the complete LaTeX document
    latex_document = """\\documentclass{article}
\\usepackage{longtable}
\\usepackage{booktabs}
\\usepackage{colortbl}
\\usepackage{pifont}
\\usepackage{xcolor}
\\usepackage{rotating}
\\usepackage{array}
\\usepackage{graphicx}

% Define extremely compact column spacing
\\setlength{\\tabcolsep}{0pt}

% Custom command for overlapping rotated column headers
\\newcommand{\\tightHeader}[3]{%
    \\multicolumn{1}{c}{\\makebox[#1pt][l]{%
        \\rotatebox[origin=bl]{45}{\\hspace{#2pt}\\raisebox{3pt}{#3}}%
    }}%
}

\\begin{document}
\\title{Topic Presence Across Crawls}
\\author{Generated Table}
\\maketitle

\\begin{longtable}{l"""

    # Add very narrow columns with minimal spacing
    for i in range(len(crawl_columns)):
        latex_document += "@{\\hspace{8pt}}c"  # Increased from 5pt to 8pt
    latex_document += "}\n"
    
    # Caption and label
    latex_document += "\\caption{Topic presence across different crawls}\\label{table:topic-counts}\\\\\n"
    
    # Table header for first page
    latex_document += "\\toprule\n"
    
    # Generate the header commands only once
    header_commands = []
    for i, label in enumerate(crawl_columns):
        # Different makebox width and horizontal shift based on column position
        width = "20" if i == 0 else "30"  # First column needs less width
        hshift = "0" if i == 0 else f"{i * 5}"  # Progressively shift columns to the right
        header_commands.append(f"\\tightHeader{{{width}}}{{{hshift}}}{{{label}}}")

    rotated_headers = " & ".join(header_commands)

    # First page header
    latex_document += "& " + rotated_headers + " \\\\\n"
    latex_document += "\\midrule\n"
    latex_document += "\\endfirsthead\n\n"

    # Continuation header for subsequent pages - reuse the same rotated headers
    latex_document += "\\multicolumn{" + str(len(crawl_columns) + 1) + "}{c}{\\tablename\\ \\thetable\\ -- \\textit{Continued from previous page}} \\\\\n"
    latex_document += "\\toprule\n"
    latex_document += "& " + rotated_headers + " \\\\\n"
    latex_document += "\\midrule\n"
    latex_document += "\\endhead\n\n"
    
    # Footer for all but the last page
    latex_document += "\\midrule\n"
    latex_document += "\\multicolumn{" + str(len(crawl_columns) + 1) + "}{r}{\\textit{Continued on next page}} \\\\\n"
    latex_document += "\\endfoot\n\n"
    
    # Footer for the last page
    latex_document += "\\bottomrule\n"
    latex_document += "\\endlastfoot\n\n"
    
    # Add the table content
    latex_document += table_content
    
    # Close the longtable and document
    latex_document += "\\end{longtable}\n\\end{document}"
    
    # For backward compatibility, keep returning the packages info as well
    packages = """% Required packages for the table
\\usepackage{longtable}    % For tables that span multiple pages
\\usepackage{booktabs}     % For nice-looking tables
\\usepackage{colortbl}     % For cell coloring
\\usepackage{pifont}       % For checkmarks and crosses
\\usepackage{xcolor}       % For text coloring
\\usepackage{rotating}     % For rotating text (e.g., column headers)
\\usepackage{array}        % For better column formatting
\\usepackage{graphicx}     % For additional transformations

% Define extremely compact column spacing
\\setlength{\\tabcolsep}{0pt}  % No spacing at all, we control manually with @{} in table definition

% Custom command for overlapping rotated column headers
\\newcommand{\\tightHeader}[3]{%
    \\multicolumn{1}{c}{\\makebox[#1pt][l]{%
        \\rotatebox[origin=bl]{45}{\\hspace{#2pt}\\raisebox{3pt}{#3}}%
    }}%
}
"""
    
    # Create unique filename based on content
    from datetime import datetime
    import os
    
    date_str = datetime.now().strftime("%Y%m%d")
    crawls_str = "_".join([col.lower().replace(" ", "_") for col in crawl_columns])
    filename = f"topic_presence_{crawls_str}_{date_str}.tex"
    
    # Save to file if RESULT_DIR is defined
    try:
        output_path = os.path.join(RESULT_DIR, filename)
        with open(output_path, "w") as f:
            f.write(latex_document)
        print(f"Complete LaTeX document saved to {output_path}")
    except (NameError, FileNotFoundError):
        print("Note: Document not saved to file. RESULT_DIR not defined or invalid.")
    
    return packages, latex_document

def format_topic_df_to_shorttable(df: pd.DataFrame) -> Tuple[str, str]:
    """Format a topic DataFrame into a summarized LaTeX table showing category completion rates.
    
    Args:
        df: DataFrame with columns:
            - category: Topic category
            - dataset: Source dataset
            - topic: Topic name
            - One column per crawl plot label containing counts
            
    Returns:
        Tuple of (required_packages, latex_document) where:
            - required_packages: LaTeX packages needed for the table (for reference)
            - latex_document: Complete, renderable LaTeX document
    """
    # Get crawl columns (all columns except category, dataset, and topic)
    crawl_columns = [col for col in df.columns if col not in ['category', 'dataset', 'topic']]
    
    # Build the table content
    table_content = ""
    
    # Group by category and dataset
    grouped = df.groupby(['category', 'dataset'])
    
    for (category, dataset), group in grouped:
        # Add category row
        # table_content += f"{category} ({dataset})"
        table_content += f"{dataset}"
        
        # Calculate completion rates for each crawl
        for col in crawl_columns:
            total_topics = len(group)
            completed_topics = sum(group[col] > 0)
            completion_rate = completed_topics / total_topics if total_topics > 0 else 0
            
            # Determine cell color based on completion rate
            if completion_rate == 1.0:
                cell_color = "green!25"
            elif completion_rate == 0.0:
                cell_color = "red!25"
            else:
                cell_color = "blue!25"
            
            # Add the fraction with colored background
            table_content += f" & \\cellcolor{{{cell_color}}}\\textcolor{{black}}{{{completed_topics}/{total_topics}}}"
        
        table_content += " \\\\\n"
        # table_content += "\\midrule\n"
    
    # Create the complete LaTeX document
    latex_document = """\\documentclass{article}
\\usepackage{longtable}
\\usepackage{booktabs}
\\usepackage{colortbl}
\\usepackage{xcolor}
\\usepackage{rotating}
\\usepackage{array}
\\usepackage{graphicx}

% Define extremely compact column spacing
\\setlength{\\tabcolsep}{0pt}

% Custom command for overlapping rotated column headers
\\newcommand{\\tightHeader}[3]{%
    \\multicolumn{1}{c}{\\makebox[#1pt][l]{%
        \\rotatebox[origin=bl]{45}{\\hspace{#2pt}\\raisebox{3pt}{#3}}%
    }}%
}

\\begin{document}
\\title{Topic Category Completion Rates}
\\author{Generated Table}
\\maketitle

\\begin{longtable}{l"""

    # Add very narrow columns with minimal spacing
    for i in range(len(crawl_columns)):
        latex_document += "@{\\hspace{3pt}}c"  # Increased from 5pt to 8pt
    latex_document += "}\n"
    
    # Caption and label
    latex_document += "\\caption{Topic category completion rates across different crawls}\\label{table:topic-completion}\\\\\n"
    
    # Table header for first page
    latex_document += "\\toprule\n"
    
    # Generate the header commands only once
    header_commands = []
    for i, label in enumerate(crawl_columns):
        # Different makebox width and horizontal shift based on column position
        width = "28" if i == 0 else f"{28 - (i * 3)}"  # First column needs less width
        hshift = "0" #if i == 0 else f"{i * 5}"  # Progressively shift columns to the right
        header_commands.append(f"\\tightHeader{{{width}}}{{{hshift}}}{{{label}}}")

    rotated_headers = " & ".join(header_commands)

    # First page header
    latex_document += "& " + rotated_headers + " \\\\\n"
    latex_document += "\\toprule\n"
    latex_document += "\\endfirsthead\n\n"

    # # Continuation header for subsequent pages - reuse the same rotated headers
    # latex_document += "\\multicolumn{" + str(len(crawl_columns) + 1) + "}{c}{\\tablename\\ \\thetable\\ -- \\textit{Continued from previous page}} \\\\\n"
    # latex_document += "\\toprule\n"
    # latex_document += "& " + rotated_headers + " \\\\\n"
    # latex_document += "\\midrule\n"
    # latex_document += "\\endhead\n\n"
    
    # # Footer for all but the last page
    # latex_document += "\\midrule\n"
    # latex_document += "\\multicolumn{" + str(len(crawl_columns) + 1) + "}{r}{\\textit{Continued on next page}} \\\\\n"
    # latex_document += "\\endfoot\n\n"
    
    # Footer for the last page
    latex_document += "\\bottomrule\n"
    latex_document += "\\endlastfoot\n\n"
    
    # Add the table content
    latex_document += table_content
    
    # Close the longtable and document
    latex_document += "\\end{longtable}\n\\end{document}"
    
    # For backward compatibility, keep returning the packages info as well
    packages = """% Required packages for the table
\\usepackage{longtable}    % For tables that span multiple pages
\\usepackage{booktabs}     % For nice-looking tables
\\usepackage{colortbl}     % For cell coloring
\\usepackage{xcolor}       % For text coloring
\\usepackage{rotating}     % For rotating text (e.g., column headers)
\\usepackage{array}        % For better column formatting
\\usepackage{graphicx}     % For additional transformations

% Define extremely compact column spacing
\\setlength{\\tabcolsep}{0pt}  % No spacing at all, we control manually with @{} in table definition

% Custom command for overlapping rotated column headers
\\newcommand{\\tightHeader}[3]{%
    \\multicolumn{1}{c}{\\makebox[#1pt][l]{%
        \\rotatebox[origin=bl]{32}{\\hspace{#2pt}\\raisebox{3pt}{#3}}%
    }}%
}
"""
    
    # Create unique filename based on content
    from datetime import datetime
    import os
    
    date_str = datetime.now().strftime("%Y%m%d")
    crawls_str = "_".join([col.lower().replace(" ", "_") for col in crawl_columns])
    filename = f"topic_completion_{crawls_str}_{date_str}.tex"
    
    # Save to file if RESULT_DIR is defined
    try:
        output_path = os.path.join(RESULT_DIR, filename)
        with open(output_path, "w") as f:
            f.write(latex_document)
        print(f"Complete LaTeX document saved to {output_path}")
    except (NameError, FileNotFoundError):
        print("Note: Document not saved to file. RESULT_DIR not defined or invalid.")
    
    return packages, latex_document

def generate_latex_match_table(df: pd.DataFrame, mode: str) -> Tuple[str, str]:
    """Wrapper function to generate a LaTeX table showing the match between two columns of a DataFrame."""
    if mode == "all_gt_topics":
        return format_topic_df_to_longtable(df)
    elif mode == "categories_only":
        return format_topic_df_to_shorttable(df)
    else:
        raise ValueError(f"Invalid mode: {mode}")

def plot_recall_curves_across_files(label_to_file: Dict[str, str], result_dir: str, max_steps: int = 20000, font_size: int = 28) -> None:
    """
    Creates a combined plot of recall curves across multiple files containing ground truth categories.
    Each file is plotted in a different color on the same subplot.
    
    Args:
        label_to_file: Dictionary mapping plot labels to file paths containing ground truth categories
        result_dir: Directory to save the output plot
        max_steps: Maximum number of topics to plot on x-axis
        font_size: Font size for the plot (default: 18)
    """
    import matplotlib.pyplot as plt
    import numpy as np
    from typing import Dict, List, Set
    
    # Set font properties
    plt.rcParams.update({'font.size': font_size, 'font.family': 'Times New Roman'})
    
    plt.figure(figsize=(4, 3))
    
    # Use a different color for each file
    colors = plt.cm.tab10(np.linspace(0, 1, len(label_to_file)))
    
    # First pass: validate all files have same ground truth categories
    gt_categories: Set[str] = set()
    for label, file_path in label_to_file.items():
        try:
            with open(file_path, 'r') as f:
                data = json.load(f)
                current_categories = set(data.keys())
                
                if not gt_categories:
                    gt_categories = current_categories
                elif gt_categories != current_categories:
                    raise ValueError(f"File {file_path} has different ground truth categories than expected")
                
        except FileNotFoundError:
            print(f"Warning: File not found: {file_path}")
            continue
        except json.JSONDecodeError:
            print(f"Warning: Could not decode JSON from {file_path}")
            continue
    
    if not gt_categories:
        print("Error: No valid ground truth categories found in any file")
        plt.close()
        return
    
    num_gt_categories = len(gt_categories)
    
    # Second pass: plot recall curves
    for (label, file_path), color in zip(label_to_file.items(), colors):
        try:
            with open(file_path, 'r') as f:
                data = json.load(f)
            
            # Extract first occurrence IDs and filter out None values
            first_occurrences = [fid for fid in data.values() if fid is not None]
            first_occurrences.sort()
            
            if not first_occurrences:
                print(f"Warning: No valid first occurrence IDs found in {file_path}")
                continue
            
            # Calculate recall at each step
            x_data = list(range(1, max_steps + 1))
            y_data = []
            
            for step in x_data:
                # Count how many categories were found by this step
                found_categories = sum(1 for fid in first_occurrences if fid <= step)
                recall = found_categories / num_gt_categories
                y_data.append(recall)
            
            # Plot this file's data
            plt.plot(x_data, y_data, label=label, color=color, alpha=0.8, linewidth=2)
            
        except FileNotFoundError:
            print(f"Warning: File not found: {file_path}")
            continue
        except json.JSONDecodeError:
            print(f"Warning: Could not decode JSON from {file_path}")
            continue
    
    plt.xlabel('Number of Topics')
    plt.ylabel('Recall')
    plt.ylim(-0.01, 1.01)  # Slightly extend y-axis for better visualization
    plt.grid(True, linestyle='-')
    
    # Position legend below the plot, centered, with horizontal entries and no frame
    plt.legend(loc='lower right', facecolor='white')
    
    # Adjust layout to prevent legend cutoff
    plt.tight_layout()
    
    # Save the plot
    date_str = datetime.now().strftime("%Y%m%d")
    # Use only alphanumeric chars and underscores from labels for filename safety
    safe_labels = ["".join(c for c in label if c.isalnum() or c == '_') for label in label_to_file.keys()]
    labels_str = "--".join(safe_labels)
    output_file = os.path.join(result_dir, f"recall_curves_comparison_{date_str}_{labels_str}.png")
    plt.savefig(output_file, bbox_inches='tight', dpi=250)
    plt.close()
    
    print(f"Recall curves comparison plot saved to {output_file}")

def plot_precision_at_k_across_files(label_to_file: Dict[str, str], result_dir: str, max_steps: int = 20000) -> None:
    """
    Creates grouped bar plots showing precision at k=10, 100, 1000 across multiple files.
    Each group represents a different file, and within each group are bars for different k values.
    Uses ELO ranking indices for ordering topics.
    
    Args:
        label_to_file: Dictionary mapping plot labels to file paths containing ranked topics
        result_dir: Directory to save the output plot
        max_steps: Maximum number of topics to consider (not used in this function but kept for signature consistency)
    """
    import matplotlib.pyplot as plt
    import numpy as np
    from typing import Dict, List, Set
    
    # Set font properties
    plt.rcParams.update({'font.size': 14, 'font.family': 'Palatino'})
    
    # Define the k values we want to measure precision at
    k_values = [10, 100, 1000]
    
    # Calculate precision at each k for each file
    precision_data = {k: [] for k in k_values}
    labels = []
    
    for label, file_path in label_to_file.items():
        try:
            with open(file_path, 'r') as f:
                data = json.load(f)
            
            # Get topics sorted by their ELO rank index
            ranked_topics = sorted(data.items(), key=lambda x: x[1]['ranking']['elo']['rank_idx'])
            
            if not ranked_topics:
                print(f"Warning: No ranked topics found in {file_path}")
                continue
            
            labels.append(label)
            
            # Calculate precision at each k
            for k in k_values:
                # Count how many topics are matches within first k ranked topics
                matches = sum(1 for _, topic_info in ranked_topics[:k] if topic_info.get('is_match', False))
                precision = matches / k
                precision_data[k].append(precision)
            
        except FileNotFoundError:
            print(f"Warning: File not found: {file_path}")
            continue
        except json.JSONDecodeError:
            print(f"Warning: Could not decode JSON from {file_path}")
            continue
        except KeyError as e:
            print(f"Warning: Missing expected key in data structure: {e}")
            continue
    
    if not labels:
        print("Error: No valid data found for any file")
        return
    
    # Create the plot
    plt.figure(figsize=(10, 6))
    
    # Set up the bar positions
    x = np.arange(len(k_values))  # the k value locations
    width = 0.25  # the width of the bars
    multiplier = 0
    
    # Plot bars for each file
    for label, color in zip(labels, plt.cm.tab10(np.linspace(0, 1, len(labels)))):
        precisions = [precision_data[k][multiplier] for k in k_values]
        offset = width * multiplier
        rects = plt.bar(x + offset, precisions, width, label=label, color=color)
        multiplier += 1
    
    # Add labels and title
    plt.xlabel('k value')
    plt.ylabel('Precision')
    plt.title('Precision at k across different files')
    plt.xticks(x + width/2, [f'k={k}' for k in k_values])
    plt.ylim(0, 1.1)  # Set y-axis limit to accommodate precision values
    
    # Add grid for better readability
    plt.grid(True, linestyle='--', alpha=0.7, axis='y')
    
    # Add legend
    plt.legend(loc='lower right')
    
    # Adjust layout to prevent label cutoff
    plt.tight_layout()
    
    # Save the plot
    date_str = datetime.now().strftime("%Y%m%d")
    # Use only alphanumeric chars and underscores from labels for filename safety
    safe_labels = ["".join(c for c in label if c.isalnum() or c == '_') for label in label_to_file.keys()]
    labels_str = "--".join(safe_labels)
    output_file = os.path.join(result_dir, f"precision_at_k_comparison_{date_str}_{labels_str}.png")
    plt.savefig(output_file, bbox_inches='tight', dpi=200)
    plt.close()
    
    print(f"Precision at k comparison plot saved to {output_file}")

def plot_recall_curves_for_gt_topics(label_to_file: Dict[str, str], result_dir: str, max_steps: int = 20000) -> None:
    """
    Creates a combined plot of recall curves across multiple files containing matched topics.
    The function extracts unique ground truth topics from the "matched_topics" field,
    finds the first occurrence of each ground truth topic, and plots recall curves.
    
    If a ground truth topic contains colons (":"), only the last part after the final colon is used
    to reduce the number of unique topics by grouping related concepts.
    All topics are converted to lowercase for case-insensitive matching.
    
    Args:
        label_to_file: Dictionary mapping plot labels to file paths containing matched topics
                      (e.g., topics_ranked_matched_*.json files)
        result_dir: Directory to save the output plot
        max_steps: Maximum number of topics to plot on x-axis
    """
    import matplotlib.pyplot as plt
    import numpy as np
    from typing import Dict, List, Set
    
    # Set font properties
    plt.rcParams.update({'font.size': 14, 'font.family': 'Palatino'})
    
    plt.figure(figsize=(6, 4))
    
    # Use a different color for each file
    colors = plt.cm.tab10(np.linspace(0, 1, len(label_to_file)))
    
    # First pass: collect all unique ground truth topics across all files
    all_gt_topics: Set[str] = set()
    
    for label, file_path in label_to_file.items():
        try:
            with open(file_path, 'r') as f:
                data = json.load(f)
                
            # Extract all matched topics
            for topic_info in data.values():
                if topic_info.get('is_match', False) and 'matched_topics' in topic_info:
                    matched_topics = topic_info['matched_topics']
                    # Filter out "None" entries and process topics
                    for topic in matched_topics:
                        if topic and topic.lower() != "none":
                            # Extract the last part after the final colon if it exists, convert to lowercase
                            processed_topic = topic.split(":")[-1].strip().lower()
                            all_gt_topics.add(processed_topic)
                    
        except FileNotFoundError:
            print(f"Warning: File not found: {file_path}")
            continue
        except json.JSONDecodeError:
            print(f"Warning: Could not decode JSON from {file_path}")
            continue
    
    if not all_gt_topics:
        print("Error: No valid ground truth topics found in any file")
        plt.close()
        return
    
    num_gt_topics = len(all_gt_topics)
    print(f"Found {num_gt_topics} unique ground truth topics across all files")
    
    # Second pass: find first occurrence of each ground truth topic and plot recall curves
    for (label, file_path), color in zip(label_to_file.items(), colors):
        try:
            with open(file_path, 'r') as f:
                data = json.load(f)
            
            # Find first occurrence of each ground truth topic
            gt_topic_to_first_occurrence = {}
            
            # Sort topics by first_occurrence_id to ensure we find the earliest occurrence
            sorted_topics = sorted(data.items(), key=lambda x: x[1].get('first_occurence_id', float('inf')))
            
            for topic_key, topic_info in sorted_topics:
                if topic_info.get('is_match', False) and 'matched_topics' in topic_info:
                    matched_topics = topic_info['matched_topics']
                    first_occurence_id = topic_info.get('first_occurence_id')
                    
                    if first_occurence_id is not None:
                        for gt_topic in matched_topics:
                            if gt_topic and gt_topic.lower() != "none":
                                # Process the topic to get the part after the last colon and convert to lowercase
                                processed_topic = gt_topic.split(":")[-1].strip().lower()
                                
                                if processed_topic in all_gt_topics:
                                    # Only record the first occurrence if it hasn't been seen before
                                    if processed_topic not in gt_topic_to_first_occurrence:
                                        gt_topic_to_first_occurrence[processed_topic] = first_occurence_id
            
            # Extract first occurrence IDs and sort them
            first_occurrences = sorted(gt_topic_to_first_occurrence.values())
            
            if not first_occurrences:
                print(f"Warning: No valid first occurrence IDs found in {file_path}")
                continue
            
            # Calculate recall at each step
            x_data = list(range(1, max_steps + 1))
            y_data = []
            
            for step in x_data:
                # Count how many ground truth topics were found by this step
                found_topics = sum(1 for fid in first_occurrences if fid <= step)
                recall = found_topics / num_gt_topics
                y_data.append(recall)
            
            # Plot this file's data
            plt.plot(x_data, y_data, label=label, color=color, alpha=0.8)
            
        except FileNotFoundError:
            print(f"Warning: File not found: {file_path}")
            continue
        except json.JSONDecodeError:
            print(f"Warning: Could not decode JSON from {file_path}")
            continue
        except Exception as e:
            print(f"Warning: Error processing {file_path}: {e}")
            continue
    
    plt.xlabel('Number of Topics')
    plt.ylabel('Recall')
    plt.ylim(-0.01, 1.01)  # Slightly extend y-axis for better visualization
    plt.grid(True, linestyle='--', alpha=0.7)
    
    # Position legend below the plot, centered, with horizontal entries and no frame
    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),
               ncol=len(label_to_file), frameon=False)
    
    # Adjust layout to prevent legend cutoff
    plt.tight_layout()
    
    # Save the plot
    date_str = datetime.now().strftime("%Y%m%d")
    # Use only alphanumeric chars and underscores from labels for filename safety
    safe_labels = ["".join(c for c in label if c.isalnum() or c == '_') for label in label_to_file.keys()]
    labels_str = "--".join(safe_labels)
    output_file = os.path.join(result_dir, f"gt_recall_curves_comparison_{date_str}_{labels_str}.png")
    plt.savefig(output_file, bbox_inches='tight', dpi=200)
    plt.close()
    
    print(f"Ground truth topic recall curves comparison plot saved to {output_file}")
    
    # Prepare overall stats
    overall_stats = {
        "total_unique_gt_topics": num_gt_topics,
        "all_unique_gt_topics": sorted(list(all_gt_topics)),  # Save all unique ground truth topics
        "per_file_stats": {}
    }
    
    # Collect stats for each file
    for label, file_path in label_to_file.items():
        try:
            with open(file_path, 'r') as f:
                data = json.load(f)
            
            # Count unique ground truth topics found in this file
            found_gt_topics = set()
            gt_topic_to_first_occurrence = {}
            gt_topic_to_first_occurrence_text = {}
            
            # Sort topics by first_occurrence_id to process in order
            sorted_topics = sorted(data.items(), key=lambda x: x[1].get('first_occurence_id', float('inf')))
            
            for topic_key, topic_info in sorted_topics:
                if topic_info.get('is_match', False) and 'matched_topics' in topic_info:
                    first_occurence_id = topic_info.get('first_occurence_id')
                    
                    for topic in topic_info['matched_topics']:
                        if topic and topic.lower() != "none":
                            # Process the topic to get the part after the last colon and convert to lowercase
                            processed_topic = topic.split(":")[-1].strip().lower()
                            found_gt_topics.add(processed_topic)
                            
                            # Record the first occurrence ID for this topic if not already recorded
                            if processed_topic not in gt_topic_to_first_occurrence and first_occurence_id is not None:
                                gt_topic_to_first_occurrence[processed_topic] = first_occurence_id
                                gt_topic_to_first_occurrence_text[processed_topic] = topic_key
            
            # Store detailed statistics for this file
            overall_stats["per_file_stats"][label] = {
                "total_gt_topics": num_gt_topics,
                "found_gt_topics_count": len(found_gt_topics),
                "found_gt_topics": sorted(list(found_gt_topics)),  # Save found ground truth topics
                "gt_topic_to_first_occurrence": gt_topic_to_first_occurrence,  # Save when each topic was found
                "gt_topic_to_first_occurrence_text": gt_topic_to_first_occurrence_text,  # Save the original topic text
                "recall": len(found_gt_topics) / num_gt_topics if num_gt_topics > 0 else 0
            }
            
        except Exception as e:
            overall_stats["per_file_stats"][label] = {"error": f"Failed to process file: {str(e)}"}
    
    # Save statistics
    stats_file = os.path.join(result_dir, f"gt_recall_stats_{date_str}_{labels_str}.json")
    with open(stats_file, 'w') as f:
        json.dump(overall_stats, f, indent=2)
    
    print(f"Ground truth topic recall statistics saved to {stats_file}")
    return overall_stats